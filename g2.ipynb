{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Apps-Apps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['training'] = df['Text']  + 'TL;DR' + df['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = df[['Summary','Text','training']][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.852\n"
     ]
    }
   ],
   "source": [
    "sum_all_tokens = sum([len(review.split()) for review in min_df['training']])\n",
    "avg_length = sum_all_tokens / len(min_df['training'])\n",
    "print(avg_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    " \n",
    "class GPT2ReviewDataset(Dataset):  \n",
    "    def __init__(self, tokenizer, reviews, max_len=100):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eos = self.tokenizer.eos_token\n",
    "        self.eos_id = self.tokenizer.eos_token_id\n",
    "        self.reviews = reviews\n",
    "        self.result = []\n",
    "\n",
    "        for review in self.reviews:\n",
    "            # Encode the text using tokenizer.encode(). We add EOS at the end\n",
    "            tokenized = self.tokenizer.encode(review + self.eos)\n",
    "            \n",
    "            # Padding/truncating the encoded sequence to max_len \n",
    "            padded = self.pad_truncate(tokenized)            \n",
    "\n",
    "            # Creating a tensor and adding to the result\n",
    "            self.result.append(torch.tensor(padded))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.result)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.result[item]\n",
    "\n",
    "    def pad_truncate(self, name):\n",
    "        extra_length = 4\n",
    "        name_length = len(name) - extra_length\n",
    "        if name_length < self.max_len:\n",
    "            difference = self.max_len - name_length\n",
    "            result = name + [self.eos_id] * difference\n",
    "        elif name_length > self.max_len:\n",
    "            result = name[:self.max_len + 3]+[self.eos_id] \n",
    "        else:\n",
    "            result = name\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device (\"cpu\")\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = min_df.head (750)\n",
    "test_df = min_df.tail (250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1430 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GPT2ReviewDataset(tokenizer, train_df['training'], 100)\n",
    "test_dataset = GPT2ReviewDataset(tokenizer, test_df['training'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, dl, epochs, device):    \n",
    "    for epoch in range(epochs):\n",
    "        print (f\"Epoch {epoch}\")\n",
    "        for idx, batch in enumerate(dl):\n",
    "             with torch.set_grad_enabled(True):\n",
    "                optimizer.zero_grad()\n",
    "                batch = batch.to(device)\n",
    "                output = model(batch, labels=batch)\n",
    "                loss = output[0]\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if idx % 50 == 0:\n",
    "                    print(\"loss: %f, %d\"%(loss, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/legolas/.local/lib/python3.11/site-packages/transformers/models/auto/modeling_auto.py:1595: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss: 7.990021, 0\n",
      "loss: 0.958284, 50\n",
      "loss: 2.280205, 100\n",
      "loss: 2.489177, 150\n",
      "loss: 3.791001, 200\n",
      "loss: 3.893262, 250\n",
      "loss: 1.879658, 300\n",
      "loss: 1.739902, 350\n",
      "loss: 2.014563, 400\n",
      "loss: 3.689391, 450\n",
      "loss: 1.533364, 500\n",
      "loss: 3.820602, 550\n",
      "loss: 2.326473, 600\n",
      "loss: 2.449049, 650\n",
      "loss: 2.228420, 700\n",
      "Epoch 1\n",
      "loss: 1.411688, 0\n",
      "loss: 0.721575, 50\n",
      "loss: 1.638689, 100\n",
      "loss: 1.892254, 150\n",
      "loss: 2.658958, 200\n",
      "loss: 2.881997, 250\n",
      "loss: 1.382528, 300\n",
      "loss: 1.297520, 350\n",
      "loss: 1.360433, 400\n",
      "loss: 2.460260, 450\n",
      "loss: 1.271334, 500\n",
      "loss: 1.774893, 550\n",
      "loss: 1.649122, 600\n",
      "loss: 1.682940, 650\n",
      "loss: 1.458864, 700\n",
      "Epoch 2\n",
      "loss: 1.080663, 0\n",
      "loss: 0.714477, 50\n",
      "loss: 0.976882, 100\n",
      "loss: 1.415865, 150\n",
      "loss: 1.685136, 200\n",
      "loss: 1.871129, 250\n",
      "loss: 0.862328, 300\n",
      "loss: 0.923563, 350\n",
      "loss: 0.821626, 400\n",
      "loss: 1.342887, 450\n",
      "loss: 0.889995, 500\n",
      "loss: 0.950819, 550\n",
      "loss: 1.001452, 600\n",
      "loss: 1.114013, 650\n",
      "loss: 0.781810, 700\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch import cuda\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelWithLMHead\n",
    "\n",
    "parameters={\n",
    "    \"BATCH_SIZE\":4,          \n",
    "    \"EPOCHS\":3,              \n",
    "    \"LEARNING_RATE\":1e-4,          \n",
    "    \"MAX_TARGET_TEXT_LENGTH\":100\n",
    "}\n",
    "\n",
    "# Load pretrained model from Hugging face\n",
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device = torch.device (\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(params = model.parameters(), lr=parameters['LEARNING_RATE'])\n",
    "train(model, optimizer, train_dataset, epochs=parameters['EPOCHS'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/tokenizer_config.json',\n",
       " 'model/special_tokens_map.json',\n",
       " 'model/vocab.json',\n",
       " 'model/merges.txt',\n",
       " 'model/added_tokens.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_directory = \"model\"\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Define directory where the model was saved\n",
    "save_directory = \"model\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "loaded_model = GPT2LMHeadModel.from_pretrained(save_directory)\n",
    "loaded_tokenizer = GPT2Tokenizer.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary (input_text):\n",
    "  input_text += \" TL;DR\"\n",
    "  tokenized_input = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "  # Generate summary\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      generated_ids = model.generate(\n",
    "          input_ids=tokenized_input.to(device),\n",
    "          max_length= 100,  # Adjust the max length as needed\n",
    "          num_beams=5,    # Adjust the number of beams for beam search\n",
    "          early_stopping=True\n",
    "      )\n",
    "\n",
    "  # Decode generated summary\n",
    "  return tokenizer.decode(generated_ids[0], skip_special_tokens=True).split (\"TL;DR\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary: : This is a great drink for those who are looking for a quick, refreshing drink.\n",
      "\n",
      "Reviewed By Date Rating Strength Flavoring Taste Room Note Emeritus Account (28392) 2008-10-29 Medium None Detected Medium Pleasant to Tolerable I\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I first had this drink when my mother brought it back with her from a visit to her home in Brittany France and thought it was delicious!  I wish it were a bit cheaper but other than that, I love this product!\"\n",
    "print(\"Generated Summary:\", generate_summary (input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = list ()\n",
    "reference = list ()\n",
    "for index, row in test_df.iterrows():\n",
    "    generated.append (generate_summary (row[\"Text\"][:100]))\n",
    "    reference.append (row[\"Summary\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge_scores = []\n",
    "for generated_text, reference_summary in zip(generated, test_df['Summary']):\n",
    "    rouge_scores.append(rouge.get_scores(generated_text, reference_summary))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE scores: {'rouge-1': {'f': 0.12873521765863918, 'p': 0.5228629789022853, 'r': 0.07385728715728716}, 'rouge-2': {'f': 0.03908225040021741, 'p': 0.21843137254901965, 'r': 0.0223}, 'rouge-l': {'f': 0.11494087063455671, 'p': 0.4528629789022853, 'r': 0.06771457431457432}}\n"
     ]
    }
   ],
   "source": [
    "avg_rouge_scores = {\n",
    "        'rouge-1': {\n",
    "            'f': sum(score[0]['rouge-1']['f'] for score in rouge_scores) / len(rouge_scores),\n",
    "            'p': sum(score[0]['rouge-1']['p'] for score in rouge_scores) / len(rouge_scores),\n",
    "            'r': sum(score[0]['rouge-1']['r'] for score in rouge_scores) / len(rouge_scores)\n",
    "        },\n",
    "        'rouge-2': {\n",
    "            'f': sum(score[0]['rouge-2']['f'] for score in rouge_scores) / len(rouge_scores),\n",
    "            'p': sum(score[0]['rouge-2']['p'] for score in rouge_scores) / len(rouge_scores),\n",
    "            'r': sum(score[0]['rouge-2']['r'] for score in rouge_scores) / len(rouge_scores)\n",
    "        },\n",
    "        'rouge-l': {\n",
    "            'f': sum(score[0]['rouge-l']['f'] for score in rouge_scores) / len(rouge_scores),\n",
    "            'p': sum(score[0]['rouge-l']['p'] for score in rouge_scores) / len(rouge_scores),\n",
    "            'r': sum(score[0]['rouge-l']['r'] for score in rouge_scores) / len(rouge_scores)\n",
    "        }\n",
    "    }\n",
    "print(f'Average ROUGE scores: {avg_rouge_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
